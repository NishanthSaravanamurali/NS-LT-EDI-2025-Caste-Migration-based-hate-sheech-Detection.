{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamil_train_embeddings = torch.tensor(np.load(r\"train_tamil_fasttext_embeddings.npy\"), dtype=torch.float32)\n",
    "tamil_dev_embeddings = torch.tensor(np.load(r\"dev_tamil_fasttext_embeddings.npy\"), dtype=torch.float32)\n",
    "tamil_test_embeddings = torch.tensor(np.load(r\"test_tamil_fasttext_embeddings.npy\"), dtype=torch.float32)\n",
    "\n",
    "tamil_eng_train_embeddings = torch.tensor(np.load(r\"train_tamil_eng_fasttext_embeddings.npy\"), dtype=torch.float32)\n",
    "tamil_eng_dev_embeddings = torch.tensor(np.load(r\"dev_tamil_eng_fasttext_embeddings.npy\"), dtype=torch.float32)\n",
    "tamil_eng_test_embeddings = torch.tensor(np.load(r\"test_tamil_eng_fasttext_embeddings.npy\"), dtype=torch.float32)\n",
    "\n",
    "y_tamil_train = np.loadtxt(r\"train_tamil_labels.txt\", dtype=int)\n",
    "y_tamil_dev = np.loadtxt(r\"dev_tamil_labels.txt\", dtype=int)\n",
    "\n",
    "y_tamil_eng_train = np.loadtxt(r\"train_tamil_eng_labels.txt\", dtype=int)\n",
    "y_tamil_eng_dev = np.loadtxt(r\"dev_tamil_eng_labels.txt\", dtype=int)\n",
    "\n",
    "\n",
    "\n",
    "#______________________________________________________________\n",
    "\n",
    "tamil_combined_embeddings = torch.cat((tamil_train_embeddings, tamil_dev_embeddings), dim=0)\n",
    "y_tamil_combined = np.concatenate((y_tamil_train, y_tamil_dev))\n",
    "\n",
    "#______________________________________________________________\n",
    "\n",
    "tamil_eng_combined_embeddings = torch.cat((tamil_eng_train_embeddings, tamil_eng_dev_embeddings), dim=0)\n",
    "y_tamil_eng_combined = np.concatenate((y_tamil_eng_train, y_tamil_eng_dev))\n",
    "\n",
    "#______________________________________________________________\n",
    "\n",
    "# ------------------ Tamil: Combine Original + English-Converted Embeddings ------------------\n",
    "final_tamil_train_embeddings = torch.cat((tamil_combined_embeddings, tamil_eng_combined_embeddings), dim=1)\n",
    "final_tamil_train_labels = y_tamil_combined  # Labels remain unchanged\n",
    "\n",
    "final_tamil_test_embeddings = torch.cat((tamil_test_embeddings, tamil_eng_test_embeddings), dim=1)\n",
    "#final_tamil_test_labels = y_tamil_test  # Labels remain unchanged\n",
    "\n",
    "# ------------------ Tamil: Combine Original + English-Converted Embeddings ------------------\n",
    "final_tamil_train_embeddings2= torch.cat((tamil_train_embeddings, tamil_eng_train_embeddings), dim=1)\n",
    "final_tamil_train_labels2 = y_tamil_train  # Labels remain unchanged\n",
    "\n",
    "final_tamil_test_embeddings2 = torch.cat((tamil_dev_embeddings, tamil_eng_dev_embeddings), dim=1)\n",
    "final_tamil_test_labels2 = y_tamil_dev  # Labels remain unchanged\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all dataset combinations\n",
    "DATASETS = {\n",
    "    \"Tamil\": (tamil_train_embeddings, tamil_dev_embeddings, y_tamil_train, y_tamil_dev),\n",
    "    \n",
    "    \"Tamil-English\": (tamil_eng_train_embeddings, tamil_eng_dev_embeddings, y_tamil_eng_train, y_tamil_eng_dev),\n",
    "    \n",
    "    \"Tamil (Original+English)\": (final_tamil_train_embeddings2, final_tamil_test_embeddings2, final_tamil_train_labels2, final_tamil_test_labels2),\n",
    "    }\n",
    "\n",
    "# Define ML models\n",
    "MODELS = {\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective='binary:logistic', eval_metric='aucpr', booster='gbtree', n_estimators=1000, max_depth=8, learning_rate=0.1, random_state=42, tree_method=\"hist\", device=\"cuda\"),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=1000, max_depth=8, random_state=42, class_weight='balanced', min_samples_split=2, min_samples_leaf=1),\n",
    "    \"SVM\": SVC(kernel='linear', probability=True,  random_state=42, class_weight='balanced', C=1.0, gamma='scale'),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=2, weights='uniform', algorithm='auto', n_jobs=-1),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,250,500,300), max_iter=2500, random_state=42),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all dataset combinations\n",
    "DATASETS = {\n",
    "    \"Tamil\": (tamil_combined_embeddings, tamil_test_embeddings, y_tamil_combined),\n",
    "    \n",
    "    \"Tamil-English\": (tamil_eng_combined_embeddings, tamil_eng_test_embeddings, y_tamil_eng_combined),\n",
    "    \n",
    "    \"Tamil (Original+English)\": (final_tamil_train_embeddings, final_tamil_test_embeddings, final_tamil_train_labels),\n",
    "    }\n",
    "\n",
    "# Define ML models\n",
    "MODELS = {\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective='binary:logistic', eval_metric='aucpr', booster='gbtree', n_estimators=1000, max_depth=8, learning_rate=0.1, random_state=42, tree_method=\"hist\", device=\"cuda\"),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, max_depth=6, random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', probability=True),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Training on dataset: Tamil ====\n",
      "\n",
      "Training model: XGBoost\n",
      "✅ Accuracy: 0.7878\n",
      "✅ F1 Score: 0.7835\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       485\n",
      "           1       0.77      0.64      0.70       302\n",
      "\n",
      "    accuracy                           0.79       787\n",
      "   macro avg       0.78      0.76      0.77       787\n",
      "weighted avg       0.79      0.79      0.78       787\n",
      "\n",
      "⏱️ Training Time: 18.02 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: Logistic Regression\n",
      "✅ Accuracy: 0.6366\n",
      "✅ F1 Score: 0.5697\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.93      0.76       485\n",
      "           1       0.59      0.17      0.27       302\n",
      "\n",
      "    accuracy                           0.64       787\n",
      "   macro avg       0.62      0.55      0.51       787\n",
      "weighted avg       0.62      0.64      0.57       787\n",
      "\n",
      "⏱️ Training Time: 0.03 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: Random Forest\n",
      "✅ Accuracy: 0.7382\n",
      "✅ F1 Score: 0.7360\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       485\n",
      "           1       0.67      0.62      0.64       302\n",
      "\n",
      "    accuracy                           0.74       787\n",
      "   macro avg       0.72      0.72      0.72       787\n",
      "weighted avg       0.74      0.74      0.74       787\n",
      "\n",
      "⏱️ Training Time: 59.85 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: SVM\n",
      "✅ Accuracy: 0.5972\n",
      "✅ F1 Score: 0.6019\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.65       485\n",
      "           1       0.48      0.57      0.52       302\n",
      "\n",
      "    accuracy                           0.60       787\n",
      "   macro avg       0.59      0.59      0.59       787\n",
      "weighted avg       0.61      0.60      0.60       787\n",
      "\n",
      "⏱️ Training Time: 18.42 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: KNN\n",
      "✅ Accuracy: 0.6595\n",
      "✅ F1 Score: 0.6354\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.75       485\n",
      "           1       0.59      0.35      0.44       302\n",
      "\n",
      "    accuracy                           0.66       787\n",
      "   macro avg       0.64      0.60      0.60       787\n",
      "weighted avg       0.65      0.66      0.64       787\n",
      "\n",
      "⏱️ Training Time: 0.00 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: MLP\n",
      "✅ Accuracy: 0.7560\n",
      "✅ F1 Score: 0.7543\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81       485\n",
      "           1       0.70      0.65      0.67       302\n",
      "\n",
      "    accuracy                           0.76       787\n",
      "   macro avg       0.74      0.74      0.74       787\n",
      "weighted avg       0.75      0.76      0.75       787\n",
      "\n",
      "⏱️ Training Time: 37.86 sec\n",
      "--------------------------------------\n",
      "\n",
      "==== Training on dataset: Tamil-English ====\n",
      "\n",
      "Training model: XGBoost\n",
      "✅ Accuracy: 0.7700\n",
      "✅ F1 Score: 0.7631\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83       485\n",
      "           1       0.76      0.59      0.66       302\n",
      "\n",
      "    accuracy                           0.77       787\n",
      "   macro avg       0.77      0.74      0.74       787\n",
      "weighted avg       0.77      0.77      0.76       787\n",
      "\n",
      "⏱️ Training Time: 18.44 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: Logistic Regression\n",
      "✅ Accuracy: 0.6302\n",
      "✅ F1 Score: 0.5675\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.91      0.75       485\n",
      "           1       0.56      0.18      0.27       302\n",
      "\n",
      "    accuracy                           0.63       787\n",
      "   macro avg       0.60      0.55      0.51       787\n",
      "weighted avg       0.61      0.63      0.57       787\n",
      "\n",
      "⏱️ Training Time: 0.03 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: Random Forest\n",
      "✅ Accuracy: 0.7052\n",
      "✅ F1 Score: 0.6939\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.78       485\n",
      "           1       0.66      0.48      0.56       302\n",
      "\n",
      "    accuracy                           0.71       787\n",
      "   macro avg       0.69      0.66      0.67       787\n",
      "weighted avg       0.70      0.71      0.69       787\n",
      "\n",
      "⏱️ Training Time: 88.97 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: SVM\n",
      "✅ Accuracy: 0.5858\n",
      "✅ F1 Score: 0.5825\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.69      0.67       485\n",
      "           1       0.46      0.42      0.44       302\n",
      "\n",
      "    accuracy                           0.59       787\n",
      "   macro avg       0.56      0.56      0.56       787\n",
      "weighted avg       0.58      0.59      0.58       787\n",
      "\n",
      "⏱️ Training Time: 60.05 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: KNN\n",
      "✅ Accuracy: 0.6747\n",
      "✅ F1 Score: 0.6421\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77       485\n",
      "           1       0.65      0.32      0.43       302\n",
      "\n",
      "    accuracy                           0.67       787\n",
      "   macro avg       0.67      0.61      0.60       787\n",
      "weighted avg       0.67      0.67      0.64       787\n",
      "\n",
      "⏱️ Training Time: 0.00 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: MLP\n",
      "✅ Accuracy: 0.7395\n",
      "✅ F1 Score: 0.7416\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78       485\n",
      "           1       0.65      0.71      0.68       302\n",
      "\n",
      "    accuracy                           0.74       787\n",
      "   macro avg       0.73      0.73      0.73       787\n",
      "weighted avg       0.75      0.74      0.74       787\n",
      "\n",
      "⏱️ Training Time: 47.73 sec\n",
      "--------------------------------------\n",
      "\n",
      "==== Training on dataset: Tamil (Original+English) ====\n",
      "\n",
      "Training model: XGBoost\n",
      "✅ Accuracy: 0.7916\n",
      "✅ F1 Score: 0.7860\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       485\n",
      "           1       0.79      0.63      0.70       302\n",
      "\n",
      "    accuracy                           0.79       787\n",
      "   macro avg       0.79      0.76      0.77       787\n",
      "weighted avg       0.79      0.79      0.79       787\n",
      "\n",
      "⏱️ Training Time: 34.91 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: Logistic Regression\n",
      "✅ Accuracy: 0.6544\n",
      "✅ F1 Score: 0.6150\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.89      0.76       485\n",
      "           1       0.61      0.28      0.38       302\n",
      "\n",
      "    accuracy                           0.65       787\n",
      "   macro avg       0.64      0.58      0.57       787\n",
      "weighted avg       0.64      0.65      0.61       787\n",
      "\n",
      "⏱️ Training Time: 0.09 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: Random Forest\n",
      "✅ Accuracy: 0.7344\n",
      "✅ F1 Score: 0.7299\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79       485\n",
      "           1       0.68      0.58      0.63       302\n",
      "\n",
      "    accuracy                           0.73       787\n",
      "   macro avg       0.72      0.71      0.71       787\n",
      "weighted avg       0.73      0.73      0.73       787\n",
      "\n",
      "⏱️ Training Time: 143.67 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: SVM\n",
      "✅ Accuracy: 0.6010\n",
      "✅ F1 Score: 0.6034\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.67       485\n",
      "           1       0.48      0.52      0.50       302\n",
      "\n",
      "    accuracy                           0.60       787\n",
      "   macro avg       0.58      0.59      0.58       787\n",
      "weighted avg       0.61      0.60      0.60       787\n",
      "\n",
      "⏱️ Training Time: 52.79 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: KNN\n",
      "✅ Accuracy: 0.6531\n",
      "✅ F1 Score: 0.6148\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.88      0.76       485\n",
      "           1       0.60      0.28      0.38       302\n",
      "\n",
      "    accuracy                           0.65       787\n",
      "   macro avg       0.63      0.58      0.57       787\n",
      "weighted avg       0.64      0.65      0.61       787\n",
      "\n",
      "⏱️ Training Time: 0.00 sec\n",
      "--------------------------------------\n",
      "\n",
      "Training model: MLP\n",
      "✅ Accuracy: 0.7662\n",
      "✅ F1 Score: 0.7668\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       485\n",
      "           1       0.69      0.71      0.70       302\n",
      "\n",
      "    accuracy                           0.77       787\n",
      "   macro avg       0.75      0.76      0.75       787\n",
      "weighted avg       0.77      0.77      0.77       787\n",
      "\n",
      "⏱️ Training Time: 37.82 sec\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for dataset_name, (X_train, X_test, y_train, y_test) in DATASETS.items():\n",
    "    print(f\"\\n==== Training on dataset: {dataset_name} ====\")\n",
    "\n",
    "    for model_name, model in MODELS.items():\n",
    "        print(f\"\\nTraining model: {model_name}\")\n",
    "\n",
    "        # Handle GPU training for XGBoost\n",
    "        if \"XGB\" not in model_name:\n",
    "            # Convert PyTorch tensors to NumPy only for non-XGBoost models\n",
    "            if isinstance(X_train, torch.Tensor):\n",
    "                X_train = X_train.cpu().numpy()\n",
    "            if isinstance(X_test, torch.Tensor):\n",
    "                X_test = X_test.cpu().numpy()\n",
    "            if isinstance(y_train, torch.Tensor):\n",
    "                y_train = y_train.cpu().numpy()\n",
    "            if isinstance(y_test, torch.Tensor):\n",
    "                y_test = y_test.cpu().numpy()\n",
    "\n",
    "        # Measure training time\n",
    "        train_start = time.time()\n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error training {model_name} on {dataset_name}: {e}\")\n",
    "            continue  # Skip to next model\n",
    "        train_end = time.time()\n",
    "        train_time = train_end - train_start  # Training duration\n",
    "\n",
    "        # Measure evaluation time\n",
    "        eval_start = time.time()\n",
    "        try:\n",
    "            y_pred = model.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "            print(f\"✅ Accuracy: {acc:.4f}\")\n",
    "            print(f\"✅ F1 Score: {f1:.4f}\")\n",
    "            print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "            print(f\"⏱️ Training Time: {train_time:.2f} sec\")\n",
    "            print(\"--------------------------------------\")\n",
    "\n",
    "            eval_end = time.time()\n",
    "            eval_time = eval_end - eval_start  # Evaluation duration\n",
    "\n",
    "            # Store results\n",
    "            results.append({\n",
    "                \"Dataset\": dataset_name,\n",
    "                \"Model\": model_name,\n",
    "                \"Accuracy\": acc,\n",
    "                \"F1 Score\": f1,\n",
    "                \"Precision\": report[\"weighted avg\"][\"precision\"],\n",
    "                \"Recall\": report[\"weighted avg\"][\"recall\"],\n",
    "                \"Training Time (sec)\": train_time,\n",
    "                \"Evaluation Time (sec)\": eval_time\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error evaluating {model_name} on {dataset_name}: {e}\")\n",
    "\n",
    "# Convert results to DataFrame and save as CSV\n",
    "#df_results = pd.DataFrame(results)\n",
    "#df_results.to_csv(\"model_results.csv\", index=False)\n",
    "#print(\"\\n✅ Results saved to 'model_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Training on dataset: Tamil ====\n",
      "\n",
      "Training model: XGBoost\n",
      "✅ Saving predictions for Tamil using XGBoost\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil_XGBoost_new.csv'\n",
      "\n",
      "Training model: Logistic Regression\n",
      "✅ Saving predictions for Tamil using Logistic Regression\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil_Logistic_Regression_new.csv'\n",
      "\n",
      "Training model: Random Forest\n",
      "✅ Saving predictions for Tamil using Random Forest\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil_Random_Forest_new.csv'\n",
      "\n",
      "Training model: SVM\n",
      "✅ Saving predictions for Tamil using SVM\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil_SVM_new.csv'\n",
      "\n",
      "Training model: KNN\n",
      "✅ Saving predictions for Tamil using KNN\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil_KNN_new.csv'\n",
      "\n",
      "Training model: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nisha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saving predictions for Tamil using MLP\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil_MLP_new.csv'\n",
      "\n",
      "==== Training on dataset: Tamil-English ====\n",
      "\n",
      "Training model: XGBoost\n",
      "✅ Saving predictions for Tamil-English using XGBoost\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil-English_XGBoost_new.csv'\n",
      "\n",
      "Training model: Logistic Regression\n",
      "✅ Saving predictions for Tamil-English using Logistic Regression\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil-English_Logistic_Regression_new.csv'\n",
      "\n",
      "Training model: Random Forest\n",
      "✅ Saving predictions for Tamil-English using Random Forest\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil-English_Random_Forest_new.csv'\n",
      "\n",
      "Training model: SVM\n",
      "✅ Saving predictions for Tamil-English using SVM\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil-English_SVM_new.csv'\n",
      "\n",
      "Training model: KNN\n",
      "✅ Saving predictions for Tamil-English using KNN\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil-English_KNN_new.csv'\n",
      "\n",
      "Training model: MLP\n",
      "✅ Saving predictions for Tamil-English using MLP\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil-English_MLP_new.csv'\n",
      "\n",
      "==== Training on dataset: Tamil (Original+English) ====\n",
      "\n",
      "Training model: XGBoost\n",
      "✅ Saving predictions for Tamil (Original+English) using XGBoost\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil_(Original+English)_XGBoost_new.csv'\n",
      "\n",
      "Training model: Logistic Regression\n",
      "✅ Saving predictions for Tamil (Original+English) using Logistic Regression\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil_(Original+English)_Logistic_Regression_new.csv'\n",
      "\n",
      "Training model: Random Forest\n",
      "✅ Saving predictions for Tamil (Original+English) using Random Forest\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil_(Original+English)_Random_Forest_new.csv'\n",
      "\n",
      "Training model: SVM\n",
      "✅ Saving predictions for Tamil (Original+English) using SVM\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil_(Original+English)_SVM_new.csv'\n",
      "\n",
      "Training model: KNN\n",
      "✅ Saving predictions for Tamil (Original+English) using KNN\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil_(Original+English)_KNN_new.csv'\n",
      "\n",
      "Training model: MLP\n",
      "✅ Saving predictions for Tamil (Original+English) using MLP\n",
      "\n",
      "✅ Predictions saved to 'submission_Tamil_(Original+English)_MLP_new.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Load test set IDs\n",
    "test_ids_df = pd.read_csv(\"test.csv\")  # Replace with actual file\n",
    "test_ids = test_ids_df[\"id\"].tolist()  # Ensure IDs match the test set order\n",
    "\n",
    "for dataset_name, (X_train, X_test, y_train) in DATASETS.items():\n",
    "    print(f\"\\n==== Training on dataset: {dataset_name} ====\")\n",
    "\n",
    "    for model_name, model in MODELS.items():\n",
    "        print(f\"\\nTraining model: {model_name}\")\n",
    "\n",
    "        # Handle GPU training for XGBoost\n",
    "        if \"XGB\" not in model_name:\n",
    "            if isinstance(X_train, torch.Tensor):\n",
    "                X_train = X_train.cpu().numpy()\n",
    "            if isinstance(X_test, torch.Tensor):\n",
    "                X_test = X_test.cpu().numpy()\n",
    "            if isinstance(y_train, torch.Tensor):\n",
    "                y_train = y_train.cpu().numpy()\n",
    "\n",
    "        # Train the model\n",
    "        train_start = time.time()\n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error training {model_name} on {dataset_name}: {e}\")\n",
    "            continue\n",
    "        train_end = time.time()\n",
    "        train_time = train_end - train_start\n",
    "\n",
    "        # Predict on test set\n",
    "        try:\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            print(f\"✅ Saving predictions for {dataset_name} using {model_name}\")\n",
    "\n",
    "            # Save predictions for this model-dataset combination\n",
    "            submission_file = f\"submission_{dataset_name.replace(' ', '_')}_{model_name.replace(' ', '_')}_new.csv\"\n",
    "            submission_df = pd.DataFrame(zip(test_ids, y_pred), columns=[\"id\", \"predictions\"])\n",
    "            submission_df.to_csv(submission_file, index=False, header=False)\n",
    "\n",
    "            print(f\"\\n✅ Predictions saved to '{submission_file}'\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error evaluating {model_name} on {dataset_name}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
